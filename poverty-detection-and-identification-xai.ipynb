{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:23:39.608590Z","iopub.execute_input":"2024-08-04T14:23:39.608961Z","iopub.status.idle":"2024-08-04T14:23:51.814118Z","shell.execute_reply.started":"2024-08-04T14:23:39.608932Z","shell.execute_reply":"2024-08-04T14:23:51.813318Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-04 14:23:41.391253: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-04 14:23:41.391355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-04 14:23:41.520665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install opendatasets\n!pip install pandas","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:23:51.816037Z","iopub.execute_input":"2024-08-04T14:23:51.816785Z","iopub.status.idle":"2024-08-04T14:24:16.977675Z","shell.execute_reply.started":"2024-08-04T14:23:51.816747Z","shell.execute_reply":"2024-08-04T14:24:16.976701Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatasets) (4.66.4)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from opendatasets) (1.6.14)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from opendatasets) (8.1.7)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2024.7.4)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.32.3)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (6.1.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->opendatasets) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.6)\nDownloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nInstalling collected packages: opendatasets\nSuccessfully installed opendatasets-0.1.22\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import opendatasets as od\nimport pandas\n\nod.download(\n\t\"https://www.kaggle.com/datasets/apollo2506/landuse-scene-classification\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:24:16.979067Z","iopub.execute_input":"2024-08-04T14:24:16.979368Z","iopub.status.idle":"2024-08-04T14:25:58.603585Z","shell.execute_reply.started":"2024-08-04T14:24:16.979328Z","shell.execute_reply":"2024-08-04T14:25:58.602550Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\nYour Kaggle username:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ayushvikasdaga\n"},{"name":"stdout","text":"Your Kaggle Key:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ································\n"},{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/apollo2506/landuse-scene-classification\nDownloading landuse-scene-classification.zip to ./landuse-scene-classification\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1.98G/1.98G [01:12<00:00, 29.6MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install torch torchvision","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:25:58.605562Z","iopub.execute_input":"2024-08-04T14:25:58.605880Z","iopub.status.idle":"2024-08-04T14:26:10.908056Z","shell.execute_reply.started":"2024-08-04T14:25:58.605855Z","shell.execute_reply":"2024-08-04T14:26:10.907052Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nimport os\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:10.909588Z","iopub.execute_input":"2024-08-04T14:26:10.909988Z","iopub.status.idle":"2024-08-04T14:26:16.057518Z","shell.execute_reply.started":"2024-08-04T14:26:10.909951Z","shell.execute_reply":"2024-08-04T14:26:16.056532Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport tensorflow as tf\n\n# Set seeds for reproducibility\nseed = 42\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nrandom.seed(seed)\n\n# If using torch, set seed for it as well\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:16.058902Z","iopub.execute_input":"2024-08-04T14:26:16.060825Z","iopub.status.idle":"2024-08-04T14:26:16.068574Z","shell.execute_reply.started":"2024-08-04T14:26:16.060796Z","shell.execute_reply":"2024-08-04T14:26:16.067868Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.applications.inception_v3 import InceptionV3\ninput_shape = (299, 299, 3)\nbase_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:16.070039Z","iopub.execute_input":"2024-08-04T14:26:16.070529Z","iopub.status.idle":"2024-08-04T14:26:21.458350Z","shell.execute_reply.started":"2024-08-04T14:26:16.070498Z","shell.execute_reply":"2024-08-04T14:26:21.457417Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.trainable = True","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.462166Z","iopub.execute_input":"2024-08-04T14:26:21.462532Z","iopub.status.idle":"2024-08-04T14:26:21.466576Z","shell.execute_reply.started":"2024-08-04T14:26:21.462507Z","shell.execute_reply":"2024-08-04T14:26:21.465695Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\n\n# Create the optimizer with the desired parameters\noptimizer = Adam(learning_rate=0.00005)\nnum_classes = 21\ninputs = keras.Input(shape=input_shape)\nx = keras.layers.GlobalAveragePooling2D(name='avg_pool')(base_model(inputs))\nx = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(x)\nmodel = keras.Model(inputs, x)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.467715Z","iopub.execute_input":"2024-08-04T14:26:21.467981Z","iopub.status.idle":"2024-08-04T14:26:21.519261Z","shell.execute_reply.started":"2024-08-04T14:26:21.467958Z","shell.execute_reply":"2024-08-04T14:26:21.518445Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef f1_score(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    return f1_val","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.520391Z","iopub.execute_input":"2024-08-04T14:26:21.520970Z","iopub.status.idle":"2024-08-04T14:26:21.527336Z","shell.execute_reply.started":"2024-08-04T14:26:21.520940Z","shell.execute_reply":"2024-08-04T14:26:21.526377Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.compile( optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', 'recall', 'precision', f1_score])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.528498Z","iopub.execute_input":"2024-08-04T14:26:21.529090Z","iopub.status.idle":"2024-08-04T14:26:21.539942Z","shell.execute_reply.started":"2024-08-04T14:26:21.529060Z","shell.execute_reply":"2024-08-04T14:26:21.539082Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_csv = pd.read_csv(\"/kaggle/working/landuse-scene-classification/train.csv\")\ntrain_images = train_csv[\"Filename\"]\ntrain_labels = train_csv[\"Label\"]\ntrain_csv","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.541107Z","iopub.execute_input":"2024-08-04T14:26:21.541649Z","iopub.status.idle":"2024-08-04T14:26:21.582278Z","shell.execute_reply.started":"2024-08-04T14:26:21.541606Z","shell.execute_reply":"2024-08-04T14:26:21.581411Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                        Filename  Label  \\\n0           5818                        runway/runway_000259.png     16   \n1           1327            intersection/intersection_000348.png     10   \n2           2529            agricultural/agricultural_000025.png      0   \n3           3865                  chaparral/chaparral_000195.png      5   \n4           2024                    airplane/airplane_000260.png      1   \n...          ...                                             ...    ...   \n7345         779        mobilehomepark/mobilehomepark_000090.png     12   \n7346        6148                parkinglot/parkinglot_000386.png     14   \n7347        1453                      freeway/freeway_000235.png      8   \n7348        5252      baseballdiamond/baseballdiamond_000144.png      2   \n7349        6722  mediumresidential/mediumresidential_000386.png     11   \n\n              ClassName  \n0                runway  \n1          intersection  \n2          agricultural  \n3             chaparral  \n4              airplane  \n...                 ...  \n7345     mobilehomepark  \n7346         parkinglot  \n7347            freeway  \n7348    baseballdiamond  \n7349  mediumresidential  \n\n[7350 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Filename</th>\n      <th>Label</th>\n      <th>ClassName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5818</td>\n      <td>runway/runway_000259.png</td>\n      <td>16</td>\n      <td>runway</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1327</td>\n      <td>intersection/intersection_000348.png</td>\n      <td>10</td>\n      <td>intersection</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2529</td>\n      <td>agricultural/agricultural_000025.png</td>\n      <td>0</td>\n      <td>agricultural</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3865</td>\n      <td>chaparral/chaparral_000195.png</td>\n      <td>5</td>\n      <td>chaparral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024</td>\n      <td>airplane/airplane_000260.png</td>\n      <td>1</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7345</th>\n      <td>779</td>\n      <td>mobilehomepark/mobilehomepark_000090.png</td>\n      <td>12</td>\n      <td>mobilehomepark</td>\n    </tr>\n    <tr>\n      <th>7346</th>\n      <td>6148</td>\n      <td>parkinglot/parkinglot_000386.png</td>\n      <td>14</td>\n      <td>parkinglot</td>\n    </tr>\n    <tr>\n      <th>7347</th>\n      <td>1453</td>\n      <td>freeway/freeway_000235.png</td>\n      <td>8</td>\n      <td>freeway</td>\n    </tr>\n    <tr>\n      <th>7348</th>\n      <td>5252</td>\n      <td>baseballdiamond/baseballdiamond_000144.png</td>\n      <td>2</td>\n      <td>baseballdiamond</td>\n    </tr>\n    <tr>\n      <th>7349</th>\n      <td>6722</td>\n      <td>mediumresidential/mediumresidential_000386.png</td>\n      <td>11</td>\n      <td>mediumresidential</td>\n    </tr>\n  </tbody>\n</table>\n<p>7350 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ntest_csv = pd.read_csv(\"/kaggle/working/landuse-scene-classification/test.csv\")\ntest_images = test_csv[\"Filename\"]\ntest_labels = test_csv[\"Label\"]\ntest_csv","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.583465Z","iopub.execute_input":"2024-08-04T14:26:21.583881Z","iopub.status.idle":"2024-08-04T14:26:21.598520Z","shell.execute_reply.started":"2024-08-04T14:26:21.583849Z","shell.execute_reply":"2024-08-04T14:26:21.597695Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                        Filename  Label  \\\n0            311                          river/river_000149.png     15   \n1            975  mediumresidential/mediumresidential_000335.png     11   \n2            547                    overpass/overpass_000338.png     13   \n3            670            storagetanks/storagetanks_000307.png     18   \n4            330                          river/river_000370.png     15   \n...          ...                                             ...    ...   \n1045         588                  chaparral/chaparral_000471.png      5   \n1046         316                          river/river_000313.png     15   \n1047        1012    denseresidential/denseresidential_000335.png      6   \n1048         855                parkinglot/parkinglot_000414.png     14   \n1049         898                parkinglot/parkinglot_000272.png     14   \n\n              ClassName  \n0                 river  \n1     mediumresidential  \n2              overpass  \n3          storagetanks  \n4                 river  \n...                 ...  \n1045          chaparral  \n1046              river  \n1047   denseresidential  \n1048         parkinglot  \n1049         parkinglot  \n\n[1050 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Filename</th>\n      <th>Label</th>\n      <th>ClassName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>311</td>\n      <td>river/river_000149.png</td>\n      <td>15</td>\n      <td>river</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>975</td>\n      <td>mediumresidential/mediumresidential_000335.png</td>\n      <td>11</td>\n      <td>mediumresidential</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>547</td>\n      <td>overpass/overpass_000338.png</td>\n      <td>13</td>\n      <td>overpass</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>670</td>\n      <td>storagetanks/storagetanks_000307.png</td>\n      <td>18</td>\n      <td>storagetanks</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>330</td>\n      <td>river/river_000370.png</td>\n      <td>15</td>\n      <td>river</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1045</th>\n      <td>588</td>\n      <td>chaparral/chaparral_000471.png</td>\n      <td>5</td>\n      <td>chaparral</td>\n    </tr>\n    <tr>\n      <th>1046</th>\n      <td>316</td>\n      <td>river/river_000313.png</td>\n      <td>15</td>\n      <td>river</td>\n    </tr>\n    <tr>\n      <th>1047</th>\n      <td>1012</td>\n      <td>denseresidential/denseresidential_000335.png</td>\n      <td>6</td>\n      <td>denseresidential</td>\n    </tr>\n    <tr>\n      <th>1048</th>\n      <td>855</td>\n      <td>parkinglot/parkinglot_000414.png</td>\n      <td>14</td>\n      <td>parkinglot</td>\n    </tr>\n    <tr>\n      <th>1049</th>\n      <td>898</td>\n      <td>parkinglot/parkinglot_000272.png</td>\n      <td>14</td>\n      <td>parkinglot</td>\n    </tr>\n  </tbody>\n</table>\n<p>1050 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nvalidation_csv = pd.read_csv(\"/kaggle/working/landuse-scene-classification/validation.csv\")\nvalidation_images = validation_csv[\"Filename\"]\nvalidation_labels = validation_csv[\"Label\"]\nvalidation_csv","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.599477Z","iopub.execute_input":"2024-08-04T14:26:21.599750Z","iopub.status.idle":"2024-08-04T14:26:21.615184Z","shell.execute_reply.started":"2024-08-04T14:26:21.599727Z","shell.execute_reply":"2024-08-04T14:26:21.614359Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                        Filename  Label  \\\n0           1928  mediumresidential/mediumresidential_000305.png     11   \n1            102                  buildings/buildings_000191.png      4   \n2            823              tenniscourt/tenniscourt_000224.png     19   \n3           2083    denseresidential/denseresidential_000436.png      6   \n4           1579      baseballdiamond/baseballdiamond_000280.png      2   \n...          ...                                             ...    ...   \n2095         652                          river/river_000094.png     15   \n2096        1803                        forest/forest_000141.png      7   \n2097        1073                    overpass/overpass_000227.png     13   \n2098        1125                  chaparral/chaparral_000321.png      5   \n2099         736            agricultural/agricultural_000104.png      0   \n\n              ClassName  \n0     mediumresidential  \n1             buildings  \n2           tenniscourt  \n3      denseresidential  \n4       baseballdiamond  \n...                 ...  \n2095              river  \n2096             forest  \n2097           overpass  \n2098          chaparral  \n2099       agricultural  \n\n[2100 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Filename</th>\n      <th>Label</th>\n      <th>ClassName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1928</td>\n      <td>mediumresidential/mediumresidential_000305.png</td>\n      <td>11</td>\n      <td>mediumresidential</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102</td>\n      <td>buildings/buildings_000191.png</td>\n      <td>4</td>\n      <td>buildings</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>823</td>\n      <td>tenniscourt/tenniscourt_000224.png</td>\n      <td>19</td>\n      <td>tenniscourt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2083</td>\n      <td>denseresidential/denseresidential_000436.png</td>\n      <td>6</td>\n      <td>denseresidential</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1579</td>\n      <td>baseballdiamond/baseballdiamond_000280.png</td>\n      <td>2</td>\n      <td>baseballdiamond</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>652</td>\n      <td>river/river_000094.png</td>\n      <td>15</td>\n      <td>river</td>\n    </tr>\n    <tr>\n      <th>2096</th>\n      <td>1803</td>\n      <td>forest/forest_000141.png</td>\n      <td>7</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>2097</th>\n      <td>1073</td>\n      <td>overpass/overpass_000227.png</td>\n      <td>13</td>\n      <td>overpass</td>\n    </tr>\n    <tr>\n      <th>2098</th>\n      <td>1125</td>\n      <td>chaparral/chaparral_000321.png</td>\n      <td>5</td>\n      <td>chaparral</td>\n    </tr>\n    <tr>\n      <th>2099</th>\n      <td>736</td>\n      <td>agricultural/agricultural_000104.png</td>\n      <td>0</td>\n      <td>agricultural</td>\n    </tr>\n  </tbody>\n</table>\n<p>2100 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Use the InceptionV3 preprocessing function\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.5,\n    height_shift_range=0.5,\n    shear_range=0.3,\n    zoom_range=0.5,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest',\n    brightness_range=[0.5, 1.5]\n)\n# Set the paths to your image directories\nimage_dir = \"/kaggle/working/landuse-scene-classification/images\"\ntrain_test_val_dir = \"/kaggle/working/landuse-scene-classification/images_train_test_val\"\n\n# Define the subdirectories for \"train,\" \"test,\" and \"validation\"\ntrain_dir = os.path.join(train_test_val_dir, \"train\")\ntest_dir = os.path.join(train_test_val_dir, \"test\")\nvalidation_dir = os.path.join(train_test_val_dir, \"validation\")\n\n# Load the training data from \"train\" directory\nimage_data_train = datagen.flow_from_dataframe(dataframe = train_csv, directory = train_dir, x_col = \"Filename\", y_col = \"ClassName\",  target_size=(299,299), batch_size=32, class_mode=\"categorical\", seed=seed)\n\n# Load the testing data from \"test\" directory\nimage_data_test = datagen.flow_from_dataframe(dataframe = test_csv, directory = test_dir, x_col = \"Filename\", y_col = \"ClassName\", target_size=(299,299), batch_size=32, class_mode=\"categorical\", seed=seed)\n\n# Load the validation data from \"validation\" directory\nimage_data_val = datagen.flow_from_dataframe(dataframe = validation_csv, directory = validation_dir, x_col = \"Filename\", y_col = \"ClassName\", target_size=(299,299), batch_size=32, class_mode=\"categorical\", seed=seed)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:26:21.616202Z","iopub.execute_input":"2024-08-04T14:26:21.616462Z","iopub.status.idle":"2024-08-04T14:26:21.767768Z","shell.execute_reply.started":"2024-08-04T14:26:21.616440Z","shell.execute_reply":"2024-08-04T14:26:21.766946Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Found 7350 validated image filenames belonging to 21 classes.\nFound 1050 validated image filenames belonging to 21 classes.\nFound 2100 validated image filenames belonging to 21 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tqdm\n!pip install keras==3.4.1\nimport keras","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:31:52.503865Z","iopub.execute_input":"2024-08-04T14:31:52.505021Z","iopub.status.idle":"2024-08-04T14:32:17.984149Z","shell.execute_reply.started":"2024-08-04T14:31:52.504978Z","shell.execute_reply":"2024-08-04T14:32:17.983096Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nCollecting keras==3.4.1\n  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (0.12.1)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (0.2.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras==3.4.1) (21.3)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras==3.4.1) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras==3.4.1) (3.1.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras==3.4.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras==3.4.1) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.2)\nDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.15.0\n    Uninstalling keras-2.15.0:\n      Successfully uninstalled keras-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nimport os\n\n# Create directory for saving models if it doesn't exist\nos.makedirs('models', exist_ok=True)\n\n# Callback for saving the best model based on validation accuracy\ncheckpoint_best = ModelCheckpoint(\n    'models/best_model.keras',\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,\n    verbose=1,\n)\n\n# Callback for saving the latest model\ncheckpoint_latest = ModelCheckpoint(\n    'models/latest_model.keras',\n    monitor='val_accuracy',\n    save_best_only=False,\n    verbose=1,\n)\n\n# Callback for logging metrics to CSV\ncsv_logger = CSVLogger('cnn_fine_tuning_log.csv', append=True, separator=';')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:32:19.943830Z","iopub.execute_input":"2024-08-04T14:32:19.944708Z","iopub.status.idle":"2024-08-04T14:32:19.950585Z","shell.execute_reply.started":"2024-08-04T14:32:19.944677Z","shell.execute_reply":"2024-08-04T14:32:19.949683Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nfrom tqdm.keras import TqdmCallback\n# Train the model\nhistory = model.fit(\n    image_data_train,\n    steps_per_epoch=32,\n    validation_data=image_data_val,\n    validation_steps=32 ,\n    epochs=50,\n    callbacks=[TqdmCallback(verbose=1), checkpoint_best, checkpoint_latest, csv_logger]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:32:22.783610Z","iopub.execute_input":"2024-08-04T14:32:22.784018Z","iopub.status.idle":"2024-08-04T15:11:49.180728Z","shell.execute_reply.started":"2024-08-04T14:32:22.783988Z","shell.execute_reply":"2024-08-04T15:11:49.179825Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"0epoch [00:00, ?epoch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3efbaf63979f4af38f9a84c36bba3359"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0batch [00:00, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722782045.713432     149 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1722782045.820767     149 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898ms/step - accuracy: 0.1614 - f1_score: 0.0038 - loss: 2.9030 - precision: 0.3125 - recall: 0.0020","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1722782083.669055     148 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.34863, saving model to models/best_model.keras\n\nEpoch 1: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.1644 - f1_score: 0.0045 - loss: 2.8949 - precision: 0.3333 - recall: 0.0024 - val_accuracy: 0.3486 - val_f1_score: 0.1609 - val_loss: 2.1679 - val_precision: 0.7949 - val_recall: 0.0908\nEpoch 2/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896ms/step - accuracy: 0.5171 - f1_score: 0.2158 - loss: 1.8768 - precision: 0.9976 - recall: 0.1253\nEpoch 2: val_accuracy improved from 0.34863 to 0.61426, saving model to models/best_model.keras\n\nEpoch 2: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.5197 - f1_score: 0.2185 - loss: 1.8697 - precision: 0.9973 - recall: 0.1271 - val_accuracy: 0.6143 - val_f1_score: 0.4430 - val_loss: 1.3946 - val_precision: 0.9099 - val_recall: 0.2959\nEpoch 3/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step - accuracy: 0.6948 - f1_score: 0.5307 - loss: 1.1720 - precision: 0.9548 - recall: 0.3718\nEpoch 3: val_accuracy improved from 0.61426 to 0.76923, saving model to models/best_model.keras\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.6951 - f1_score: 0.5318 - loss: 1.1700 - precision: 0.9545 - recall: 0.3729 - val_accuracy: 0.7692 - val_f1_score: 0.6433 - val_loss: 0.8336 - val_precision: 0.8438 - val_recall: 0.5192\nEpoch 4/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7975 - f1_score: 0.7109 - loss: 0.8404 - precision: 0.9247 - recall: 0.5807\nEpoch 4: val_accuracy did not improve from 0.76923\n\nEpoch 4: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.7973 - f1_score: 0.7116 - loss: 0.8386 - precision: 0.9250 - recall: 0.5815 - val_accuracy: 0.7686 - val_f1_score: 0.7368 - val_loss: 0.7873 - val_precision: 0.8836 - val_recall: 0.6377\nEpoch 5/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.7877 - f1_score: 0.7669 - loss: 0.7280 - precision: 0.9286 - recall: 0.6577\nEpoch 5: val_accuracy improved from 0.76923 to 0.80957, saving model to models/best_model.keras\n\nEpoch 5: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.7880 - f1_score: 0.7675 - loss: 0.7263 - precision: 0.9288 - recall: 0.6584 - val_accuracy: 0.8096 - val_f1_score: 0.8077 - val_loss: 0.6265 - val_precision: 0.8899 - val_recall: 0.7422\nEpoch 6/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8333 - f1_score: 0.8063 - loss: 0.5955 - precision: 0.9171 - recall: 0.7221\nEpoch 6: val_accuracy improved from 0.80957 to 0.84615, saving model to models/best_model.keras\n\nEpoch 6: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 387ms/step - accuracy: 0.8333 - f1_score: 0.8067 - loss: 0.5949 - precision: 0.9171 - recall: 0.7227 - val_accuracy: 0.8462 - val_f1_score: 0.8265 - val_loss: 0.5783 - val_precision: 0.9286 - val_recall: 0.7500\nEpoch 7/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.8482 - f1_score: 0.8421 - loss: 0.5077 - precision: 0.9283 - recall: 0.7720\nEpoch 7: val_accuracy did not improve from 0.84615\n\nEpoch 7: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.8480 - f1_score: 0.8419 - loss: 0.5079 - precision: 0.9280 - recall: 0.7718 - val_accuracy: 0.8408 - val_f1_score: 0.8505 - val_loss: 0.4953 - val_precision: 0.9008 - val_recall: 0.8066\nEpoch 8/50\n\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.8543 - f1_score: 0.8076 - loss: 0.5387 - precision: 0.8844 - recall: 0.7470\nEpoch 8: val_accuracy did not improve from 0.84615\n\nEpoch 8: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 995ms/step - accuracy: 0.8415 - f1_score: 0.8170 - loss: 0.5330 - precision: 0.8976 - recall: 0.7537 - val_accuracy: 0.8457 - val_f1_score: 0.8471 - val_loss: 0.4889 - val_precision: 0.8984 - val_recall: 0.8027\nEpoch 9/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918ms/step - accuracy: 0.8610 - f1_score: 0.8595 - loss: 0.4852 - precision: 0.9347 - recall: 0.7981\nEpoch 9: val_accuracy improved from 0.84615 to 0.88462, saving model to models/best_model.keras\n\nEpoch 9: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.8611 - f1_score: 0.8596 - loss: 0.4845 - precision: 0.9346 - recall: 0.7983 - val_accuracy: 0.8846 - val_f1_score: 0.8734 - val_loss: 0.3467 - val_precision: 0.8824 - val_recall: 0.8654\nEpoch 10/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888ms/step - accuracy: 0.8419 - f1_score: 0.8551 - loss: 0.4616 - precision: 0.9164 - recall: 0.8041\nEpoch 10: val_accuracy improved from 0.88462 to 0.88672, saving model to models/best_model.keras\n\nEpoch 10: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.8417 - f1_score: 0.8548 - loss: 0.4624 - precision: 0.9163 - recall: 0.8036 - val_accuracy: 0.8867 - val_f1_score: 0.8839 - val_loss: 0.3691 - val_precision: 0.9235 - val_recall: 0.8486\nEpoch 11/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.8626 - f1_score: 0.8551 - loss: 0.4746 - precision: 0.9363 - recall: 0.7900\nEpoch 11: val_accuracy improved from 0.88672 to 0.90234, saving model to models/best_model.keras\n\nEpoch 11: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.8627 - f1_score: 0.8555 - loss: 0.4734 - precision: 0.9362 - recall: 0.7907 - val_accuracy: 0.9023 - val_f1_score: 0.8998 - val_loss: 0.3433 - val_precision: 0.9433 - val_recall: 0.8613\nEpoch 12/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714ms/step - accuracy: 0.8711 - f1_score: 0.8730 - loss: 0.4504 - precision: 0.9289 - recall: 0.8244\nEpoch 12: val_accuracy did not improve from 0.90234\n\nEpoch 12: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 790ms/step - accuracy: 0.8712 - f1_score: 0.8730 - loss: 0.4498 - precision: 0.9289 - recall: 0.8243 - val_accuracy: 0.8846 - val_f1_score: 0.9032 - val_loss: 0.3681 - val_precision: 0.9000 - val_recall: 0.8654\nEpoch 13/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874ms/step - accuracy: 0.8907 - f1_score: 0.8895 - loss: 0.3779 - precision: 0.9437 - recall: 0.8414\nEpoch 13: val_accuracy did not improve from 0.90234\n\nEpoch 13: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8906 - f1_score: 0.8895 - loss: 0.3780 - precision: 0.9436 - recall: 0.8414 - val_accuracy: 0.8809 - val_f1_score: 0.8847 - val_loss: 0.3874 - val_precision: 0.9245 - val_recall: 0.8486\nEpoch 14/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.8653 - f1_score: 0.8651 - loss: 0.4076 - precision: 0.9168 - recall: 0.8202\nEpoch 14: val_accuracy did not improve from 0.90234\n\nEpoch 14: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8657 - f1_score: 0.8655 - loss: 0.4069 - precision: 0.9172 - recall: 0.8205 - val_accuracy: 0.8691 - val_f1_score: 0.8647 - val_loss: 0.4222 - val_precision: 0.8973 - val_recall: 0.8359\nEpoch 15/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9011 - f1_score: 0.9008 - loss: 0.3698 - precision: 0.9446 - recall: 0.8630\nEpoch 15: val_accuracy improved from 0.90234 to 0.92308, saving model to models/best_model.keras\n\nEpoch 15: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 360ms/step - accuracy: 0.9009 - f1_score: 0.9007 - loss: 0.3700 - precision: 0.9445 - recall: 0.8628 - val_accuracy: 0.9231 - val_f1_score: 0.9012 - val_loss: 0.2721 - val_precision: 0.9388 - val_recall: 0.8846\nEpoch 16/50\n\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.8980 - f1_score: 0.8948 - loss: 0.3686 - precision: 0.9429 - recall: 0.8523\nEpoch 16: val_accuracy did not improve from 0.92308\n\nEpoch 16: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.9005 - f1_score: 0.8981 - loss: 0.3585 - precision: 0.9429 - recall: 0.8581 - val_accuracy: 0.8965 - val_f1_score: 0.8901 - val_loss: 0.3544 - val_precision: 0.9262 - val_recall: 0.8584\nEpoch 17/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step - accuracy: 0.8960 - f1_score: 0.8840 - loss: 0.3524 - precision: 0.9284 - recall: 0.8453\nEpoch 17: val_accuracy did not improve from 0.92308\n\nEpoch 17: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.8964 - f1_score: 0.8845 - loss: 0.3513 - precision: 0.9288 - recall: 0.8459 - val_accuracy: 0.8877 - val_f1_score: 0.8934 - val_loss: 0.3390 - val_precision: 0.9275 - val_recall: 0.8623\nEpoch 18/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887ms/step - accuracy: 0.9027 - f1_score: 0.9063 - loss: 0.2829 - precision: 0.9414 - recall: 0.8756\nEpoch 18: val_accuracy did not improve from 0.92308\n\nEpoch 18: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 967ms/step - accuracy: 0.9026 - f1_score: 0.9061 - loss: 0.2838 - precision: 0.9412 - recall: 0.8754 - val_accuracy: 0.8846 - val_f1_score: 0.8875 - val_loss: 0.4126 - val_precision: 0.9184 - val_recall: 0.8654\nEpoch 19/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873ms/step - accuracy: 0.9036 - f1_score: 0.9093 - loss: 0.3288 - precision: 0.9444 - recall: 0.8777\nEpoch 19: val_accuracy did not improve from 0.92308\n\nEpoch 19: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9034 - f1_score: 0.9091 - loss: 0.3290 - precision: 0.9441 - recall: 0.8775 - val_accuracy: 0.9072 - val_f1_score: 0.9051 - val_loss: 0.2981 - val_precision: 0.9382 - val_recall: 0.8750\nEpoch 20/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - accuracy: 0.9111 - f1_score: 0.9066 - loss: 0.2909 - precision: 0.9396 - recall: 0.8764\nEpoch 20: val_accuracy did not improve from 0.92308\n\nEpoch 20: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9110 - f1_score: 0.9066 - loss: 0.2912 - precision: 0.9397 - recall: 0.8765 - val_accuracy: 0.9053 - val_f1_score: 0.9087 - val_loss: 0.3007 - val_precision: 0.9405 - val_recall: 0.8799\nEpoch 21/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.9034 - f1_score: 0.9090 - loss: 0.2822 - precision: 0.9426 - recall: 0.8786\nEpoch 21: val_accuracy did not improve from 0.92308\n\nEpoch 21: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 793ms/step - accuracy: 0.9035 - f1_score: 0.9090 - loss: 0.2824 - precision: 0.9426 - recall: 0.8786 - val_accuracy: 0.8846 - val_f1_score: 0.8693 - val_loss: 0.3718 - val_precision: 0.9167 - val_recall: 0.8462\nEpoch 22/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.9109 - f1_score: 0.9122 - loss: 0.2768 - precision: 0.9403 - recall: 0.8864\nEpoch 22: val_accuracy did not improve from 0.92308\n\nEpoch 22: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9108 - f1_score: 0.9122 - loss: 0.2770 - precision: 0.9402 - recall: 0.8864 - val_accuracy: 0.9189 - val_f1_score: 0.9149 - val_loss: 0.2776 - val_precision: 0.9430 - val_recall: 0.8887\nEpoch 23/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - accuracy: 0.9252 - f1_score: 0.9242 - loss: 0.2471 - precision: 0.9498 - recall: 0.9016\nEpoch 23: val_accuracy did not improve from 0.92308\n\nEpoch 23: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.9251 - f1_score: 0.9241 - loss: 0.2481 - precision: 0.9498 - recall: 0.9013 - val_accuracy: 0.8916 - val_f1_score: 0.8951 - val_loss: 0.3236 - val_precision: 0.9242 - val_recall: 0.8691\nEpoch 24/50\n\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.9227 - f1_score: 0.9240 - loss: 0.2574 - precision: 0.9493 - recall: 0.9005\nEpoch 24: val_accuracy did not improve from 0.92308\n\nEpoch 24: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.9136 - f1_score: 0.9184 - loss: 0.3026 - precision: 0.9417 - recall: 0.8967 - val_accuracy: 0.8462 - val_f1_score: 0.8727 - val_loss: 0.3278 - val_precision: 0.9167 - val_recall: 0.8462\nEpoch 25/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918ms/step - accuracy: 0.9197 - f1_score: 0.9202 - loss: 0.2577 - precision: 0.9461 - recall: 0.8962\nEpoch 25: val_accuracy did not improve from 0.92308\n\nEpoch 25: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.9196 - f1_score: 0.9201 - loss: 0.2580 - precision: 0.9461 - recall: 0.8960 - val_accuracy: 0.9121 - val_f1_score: 0.9127 - val_loss: 0.2892 - val_precision: 0.9363 - val_recall: 0.8906\nEpoch 26/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889ms/step - accuracy: 0.9071 - f1_score: 0.9134 - loss: 0.2641 - precision: 0.9422 - recall: 0.8865\nEpoch 26: val_accuracy improved from 0.92308 to 0.92773, saving model to models/best_model.keras\n\nEpoch 26: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9074 - f1_score: 0.9136 - loss: 0.2638 - precision: 0.9425 - recall: 0.8866 - val_accuracy: 0.9277 - val_f1_score: 0.9280 - val_loss: 0.2279 - val_precision: 0.9453 - val_recall: 0.9121\nEpoch 27/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - accuracy: 0.9222 - f1_score: 0.9248 - loss: 0.2569 - precision: 0.9516 - recall: 0.9001\nEpoch 27: val_accuracy did not improve from 0.92773\n\nEpoch 27: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 908ms/step - accuracy: 0.9222 - f1_score: 0.9248 - loss: 0.2573 - precision: 0.9517 - recall: 0.9001 - val_accuracy: 0.9231 - val_f1_score: 0.9266 - val_loss: 0.2445 - val_precision: 0.9400 - val_recall: 0.9038\nEpoch 28/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873ms/step - accuracy: 0.9150 - f1_score: 0.9109 - loss: 0.2815 - precision: 0.9384 - recall: 0.8860\nEpoch 28: val_accuracy did not improve from 0.92773\n\nEpoch 28: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9148 - f1_score: 0.9109 - loss: 0.2817 - precision: 0.9385 - recall: 0.8858 - val_accuracy: 0.9121 - val_f1_score: 0.9137 - val_loss: 0.2883 - val_precision: 0.9320 - val_recall: 0.8965\nEpoch 29/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.8998 - f1_score: 0.8977 - loss: 0.3102 - precision: 0.9291 - recall: 0.8713\nEpoch 29: val_accuracy did not improve from 0.92773\n\nEpoch 29: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9001 - f1_score: 0.8980 - loss: 0.3097 - precision: 0.9293 - recall: 0.8717 - val_accuracy: 0.9131 - val_f1_score: 0.9106 - val_loss: 0.2955 - val_precision: 0.9307 - val_recall: 0.8916\nEpoch 30/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 0.9054 - f1_score: 0.9059 - loss: 0.3071 - precision: 0.9280 - recall: 0.8854\nEpoch 30: val_accuracy improved from 0.92773 to 0.96154, saving model to models/best_model.keras\n\nEpoch 30: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 632ms/step - accuracy: 0.9057 - f1_score: 0.9062 - loss: 0.3061 - precision: 0.9282 - recall: 0.8858 - val_accuracy: 0.9615 - val_f1_score: 0.9671 - val_loss: 0.1587 - val_precision: 0.9804 - val_recall: 0.9615\nEpoch 31/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795ms/step - accuracy: 0.9432 - f1_score: 0.9406 - loss: 0.1976 - precision: 0.9725 - recall: 0.9121\nEpoch 31: val_accuracy did not improve from 0.96154\n\nEpoch 31: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9433 - f1_score: 0.9406 - loss: 0.1972 - precision: 0.9724 - recall: 0.9123 - val_accuracy: 0.9258 - val_f1_score: 0.9298 - val_loss: 0.2447 - val_precision: 0.9529 - val_recall: 0.9082\nEpoch 32/50\n\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.9306 - f1_score: 0.9479 - loss: 0.2372 - precision: 0.9698 - recall: 0.9274\nEpoch 32: val_accuracy did not improve from 0.96154\n\nEpoch 32: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 988ms/step - accuracy: 0.9193 - f1_score: 0.9339 - loss: 0.2693 - precision: 0.9546 - recall: 0.9145 - val_accuracy: 0.9326 - val_f1_score: 0.9342 - val_loss: 0.2186 - val_precision: 0.9551 - val_recall: 0.9150\nEpoch 33/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923ms/step - accuracy: 0.9167 - f1_score: 0.9167 - loss: 0.2769 - precision: 0.9457 - recall: 0.8904\nEpoch 33: val_accuracy did not improve from 0.96154\n\nEpoch 33: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 998ms/step - accuracy: 0.9166 - f1_score: 0.9167 - loss: 0.2771 - precision: 0.9456 - recall: 0.8905 - val_accuracy: 0.8846 - val_f1_score: 0.8625 - val_loss: 0.4860 - val_precision: 0.9167 - val_recall: 0.8462\nEpoch 34/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897ms/step - accuracy: 0.9306 - f1_score: 0.9314 - loss: 0.2231 - precision: 0.9566 - recall: 0.9089\nEpoch 34: val_accuracy did not improve from 0.96154\n\nEpoch 34: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9304 - f1_score: 0.9313 - loss: 0.2238 - precision: 0.9564 - recall: 0.9088 - val_accuracy: 0.9326 - val_f1_score: 0.9321 - val_loss: 0.2390 - val_precision: 0.9550 - val_recall: 0.9111\nEpoch 35/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822ms/step - accuracy: 0.9264 - f1_score: 0.9305 - loss: 0.2460 - precision: 0.9532 - recall: 0.9135\nEpoch 35: val_accuracy did not improve from 0.96154\n\nEpoch 35: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9262 - f1_score: 0.9302 - loss: 0.2465 - precision: 0.9530 - recall: 0.9132 - val_accuracy: 0.9248 - val_f1_score: 0.9267 - val_loss: 0.2367 - val_precision: 0.9489 - val_recall: 0.9062\nEpoch 36/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.9101 - f1_score: 0.9124 - loss: 0.3254 - precision: 0.9292 - recall: 0.8962\nEpoch 36: val_accuracy did not improve from 0.96154\n\nEpoch 36: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 788ms/step - accuracy: 0.9105 - f1_score: 0.9128 - loss: 0.3235 - precision: 0.9296 - recall: 0.8967 - val_accuracy: 0.9038 - val_f1_score: 0.9158 - val_loss: 0.2269 - val_precision: 0.9200 - val_recall: 0.8846\nEpoch 37/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878ms/step - accuracy: 0.9296 - f1_score: 0.9292 - loss: 0.2440 - precision: 0.9513 - recall: 0.9086\nEpoch 37: val_accuracy did not improve from 0.96154\n\nEpoch 37: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9297 - f1_score: 0.9294 - loss: 0.2435 - precision: 0.9514 - recall: 0.9089 - val_accuracy: 0.9141 - val_f1_score: 0.9132 - val_loss: 0.2898 - val_precision: 0.9355 - val_recall: 0.8926\nEpoch 38/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.9488 - f1_score: 0.9490 - loss: 0.1778 - precision: 0.9633 - recall: 0.9354\nEpoch 38: val_accuracy did not improve from 0.96154\n\nEpoch 38: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9487 - f1_score: 0.9490 - loss: 0.1781 - precision: 0.9635 - recall: 0.9352 - val_accuracy: 0.9219 - val_f1_score: 0.9218 - val_loss: 0.2505 - val_precision: 0.9401 - val_recall: 0.9043\nEpoch 39/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9357 - f1_score: 0.9386 - loss: 0.2065 - precision: 0.9563 - recall: 0.9223\nEpoch 39: val_accuracy did not improve from 0.96154\n\nEpoch 39: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 298ms/step - accuracy: 0.9356 - f1_score: 0.9386 - loss: 0.2068 - precision: 0.9563 - recall: 0.9222 - val_accuracy: 0.9423 - val_f1_score: 0.9549 - val_loss: 0.2357 - val_precision: 0.9796 - val_recall: 0.9231\nEpoch 40/50\n\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - accuracy: 0.9418 - f1_score: 0.9373 - loss: 0.1762 - precision: 0.9560 - recall: 0.9195\nEpoch 40: val_accuracy did not improve from 0.96154\n\nEpoch 40: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.9552 - f1_score: 0.9516 - loss: 0.1474 - precision: 0.9657 - recall: 0.9384 - val_accuracy: 0.9297 - val_f1_score: 0.9287 - val_loss: 0.2602 - val_precision: 0.9490 - val_recall: 0.9092\nEpoch 41/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916ms/step - accuracy: 0.9065 - f1_score: 0.9131 - loss: 0.2843 - precision: 0.9415 - recall: 0.8868\nEpoch 41: val_accuracy did not improve from 0.96154\n\nEpoch 41: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.9072 - f1_score: 0.9137 - loss: 0.2828 - precision: 0.9420 - recall: 0.8874 - val_accuracy: 0.9326 - val_f1_score: 0.9376 - val_loss: 0.2042 - val_precision: 0.9563 - val_recall: 0.9199\nEpoch 42/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890ms/step - accuracy: 0.9417 - f1_score: 0.9417 - loss: 0.2081 - precision: 0.9628 - recall: 0.9222\nEpoch 42: val_accuracy did not improve from 0.96154\n\nEpoch 42: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 967ms/step - accuracy: 0.9414 - f1_score: 0.9416 - loss: 0.2082 - precision: 0.9627 - recall: 0.9220 - val_accuracy: 0.8846 - val_f1_score: 0.9064 - val_loss: 0.3677 - val_precision: 0.9574 - val_recall: 0.8654\nEpoch 43/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868ms/step - accuracy: 0.9339 - f1_score: 0.9396 - loss: 0.2045 - precision: 0.9632 - recall: 0.9180\nEpoch 43: val_accuracy did not improve from 0.96154\n\nEpoch 43: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9339 - f1_score: 0.9395 - loss: 0.2042 - precision: 0.9630 - recall: 0.9179 - val_accuracy: 0.9229 - val_f1_score: 0.9259 - val_loss: 0.2282 - val_precision: 0.9469 - val_recall: 0.9062\nEpoch 44/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step - accuracy: 0.9613 - f1_score: 0.9513 - loss: 0.1822 - precision: 0.9692 - recall: 0.9346\nEpoch 44: val_accuracy did not improve from 0.96154\n\nEpoch 44: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9610 - f1_score: 0.9511 - loss: 0.1827 - precision: 0.9689 - recall: 0.9344 - val_accuracy: 0.9219 - val_f1_score: 0.9246 - val_loss: 0.2538 - val_precision: 0.9506 - val_recall: 0.9014\nEpoch 45/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.9423 - f1_score: 0.9489 - loss: 0.1729 - precision: 0.9625 - recall: 0.9359\nEpoch 45: val_accuracy did not improve from 0.96154\n\nEpoch 45: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 807ms/step - accuracy: 0.9423 - f1_score: 0.9487 - loss: 0.1735 - precision: 0.9624 - recall: 0.9358 - val_accuracy: 0.9423 - val_f1_score: 0.9512 - val_loss: 0.2276 - val_precision: 0.9608 - val_recall: 0.9423\nEpoch 46/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861ms/step - accuracy: 0.9277 - f1_score: 0.9284 - loss: 0.2072 - precision: 0.9494 - recall: 0.9084\nEpoch 46: val_accuracy did not improve from 0.96154\n\nEpoch 46: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9276 - f1_score: 0.9284 - loss: 0.2074 - precision: 0.9493 - recall: 0.9084 - val_accuracy: 0.9160 - val_f1_score: 0.9174 - val_loss: 0.2849 - val_precision: 0.9369 - val_recall: 0.8994\nEpoch 47/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - accuracy: 0.9179 - f1_score: 0.9181 - loss: 0.2720 - precision: 0.9448 - recall: 0.8932\nEpoch 47: val_accuracy did not improve from 0.96154\n\nEpoch 47: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.9182 - f1_score: 0.9184 - loss: 0.2710 - precision: 0.9451 - recall: 0.8936 - val_accuracy: 0.9277 - val_f1_score: 0.9286 - val_loss: 0.2259 - val_precision: 0.9472 - val_recall: 0.9111\nEpoch 48/50\n\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.9461 - f1_score: 0.9503 - loss: 0.1172 - precision: 0.9734 - recall: 0.9285\nEpoch 48: val_accuracy did not improve from 0.96154\n\nEpoch 48: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.9560 - f1_score: 0.9559 - loss: 0.1171 - precision: 0.9773 - recall: 0.9358 - val_accuracy: 0.9423 - val_f1_score: 0.9549 - val_loss: 0.1520 - val_precision: 0.9796 - val_recall: 0.9231\nEpoch 49/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928ms/step - accuracy: 0.9256 - f1_score: 0.9356 - loss: 0.2141 - precision: 0.9681 - recall: 0.9061\nEpoch 49: val_accuracy did not improve from 0.96154\n\nEpoch 49: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.9258 - f1_score: 0.9358 - loss: 0.2140 - precision: 0.9680 - recall: 0.9066 - val_accuracy: 0.9395 - val_f1_score: 0.9408 - val_loss: 0.2105 - val_precision: 0.9594 - val_recall: 0.9238\nEpoch 50/50\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892ms/step - accuracy: 0.9551 - f1_score: 0.9549 - loss: 0.1734 - precision: 0.9692 - recall: 0.9412\nEpoch 50: val_accuracy did not improve from 0.96154\n\nEpoch 50: saving model to models/latest_model.keras\n\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.9550 - f1_score: 0.9548 - loss: 0.1737 - precision: 0.9690 - recall: 0.9411 - val_accuracy: 0.9316 - val_f1_score: 0.9330 - val_loss: 0.1934 - val_precision: 0.9467 - val_recall: 0.9199\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install h5py\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:17:26.641021Z","iopub.execute_input":"2024-08-04T15:17:26.641436Z","iopub.status.idle":"2024-08-04T15:17:38.756132Z","shell.execute_reply.started":"2024-08-04T15:17:26.641403Z","shell.execute_reply":"2024-08-04T15:17:38.754941Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (3.10.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from h5py) (1.26.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights('/kaggle/working/models/best_model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:19:12.141651Z","iopub.execute_input":"2024-08-04T15:19:12.142526Z","iopub.status.idle":"2024-08-04T15:20:00.782245Z","shell.execute_reply.started":"2024-08-04T15:19:12.142494Z","shell.execute_reply":"2024-08-04T15:20:00.781217Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n# Evaluate the model on the test dataset\ntest_loss, test_accuracy, test_recall, test_precision, test_f1 = model.evaluate(image_data_test)\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {test_accuracy}')\nprint(f'Test Recall: {test_recall}')\nprint(f'Test Precision: {test_precision}')\nprint(f'Test F1 Score: {test_f1}')\n\n# Predict the labels for the test dataset\npredictions = model.predict(image_data_test)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = image_data_test.classes\nclass_labels = list(image_data_test.class_indices.keys())\n\n# Print classification report\nfrom sklearn.metrics import classification_report\nreport = classification_report(true_classes, predicted_classes, target_names=class_labels)\nprint(report)\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\nprint(conf_matrix)\n\n# Save classification report to CSV\nreport_dict = classification_report(true_classes, predicted_classes, target_names=class_labels, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\nreport_df.to_csv('classification_report.csv', index=True)\n\n# Save confusion matrix to CSV\nconf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\nconf_matrix_df.to_csv('confusion_matrix.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:34:08.424437Z","iopub.execute_input":"2024-08-04T15:34:08.425155Z","iopub.status.idle":"2024-08-04T15:35:13.055821Z","shell.execute_reply.started":"2024-08-04T15:34:08.425120Z","shell.execute_reply":"2024-08-04T15:35:13.054925Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 930ms/step - accuracy: 0.9279 - f1_score: 0.9277 - loss: 0.2678 - precision: 0.9447 - recall: 0.9122\nTest Loss: 0.2536562979221344\nTest Accuracy: 0.9266666769981384\nTest Recall: 0.907619059085846\nTest Precision: 0.9463753700256348\nTest F1 Score: 0.9263879656791687\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 914ms/step\n                   precision    recall  f1-score   support\n\n     agricultural       0.04      0.04      0.04        50\n         airplane       0.04      0.04      0.04        50\n  baseballdiamond       0.06      0.06      0.06        50\n            beach       0.07      0.08      0.07        50\n        buildings       0.05      0.06      0.06        50\n        chaparral       0.00      0.00      0.00        50\n denseresidential       0.05      0.06      0.05        50\n           forest       0.04      0.04      0.04        50\n          freeway       0.00      0.00      0.00        50\n       golfcourse       0.06      0.06      0.06        50\n           harbor       0.04      0.04      0.04        50\n     intersection       0.00      0.00      0.00        50\nmediumresidential       0.02      0.02      0.02        50\n   mobilehomepark       0.04      0.04      0.04        50\n         overpass       0.02      0.02      0.02        50\n       parkinglot       0.06      0.06      0.06        50\n            river       0.05      0.04      0.04        50\n           runway       0.08      0.08      0.08        50\nsparseresidential       0.05      0.04      0.04        50\n     storagetanks       0.09      0.08      0.09        50\n      tenniscourt       0.02      0.02      0.02        50\n\n         accuracy                           0.04      1050\n        macro avg       0.04      0.04      0.04      1050\n     weighted avg       0.04      0.04      0.04      1050\n\n[[2 4 3 3 4 3 2 2 1 2 1 1 2 3 2 2 1 3 3 4 2]\n [3 2 2 4 4 0 3 1 2 5 1 2 2 4 4 4 0 2 4 1 0]\n [1 2 3 2 4 5 4 4 3 1 0 1 4 1 0 1 2 3 2 3 4]\n [3 3 0 4 2 2 6 1 1 1 1 3 1 5 5 1 2 3 0 2 4]\n [1 1 0 2 3 4 7 4 3 4 3 2 1 4 0 3 2 2 0 1 3]\n [3 4 1 5 1 0 2 3 3 2 4 4 2 0 2 3 3 2 1 3 2]\n [2 4 5 4 2 2 3 1 1 0 2 3 5 3 1 4 1 0 1 2 4]\n [2 1 3 0 3 7 1 2 3 2 2 5 4 1 2 2 1 0 3 2 4]\n [2 2 3 0 2 3 3 3 0 2 2 2 2 4 3 0 4 2 1 3 7]\n [3 3 1 5 2 2 2 0 1 3 3 2 0 4 2 2 3 3 3 3 3]\n [2 1 1 3 2 3 2 2 2 5 2 1 3 2 3 3 5 3 1 1 3]\n [5 1 3 4 4 3 2 2 3 2 2 0 3 1 1 2 1 4 4 3 0]\n [3 2 3 3 2 1 2 6 4 1 1 3 1 2 1 4 3 3 3 1 1]\n [1 1 3 1 3 1 6 4 2 4 3 2 3 2 3 3 3 1 3 1 0]\n [3 1 5 3 2 0 2 2 2 5 3 1 3 3 1 5 2 2 4 0 1]\n [3 2 4 4 2 0 3 2 2 2 4 5 1 1 2 3 1 3 1 2 3]\n [3 2 0 4 3 4 3 2 2 1 4 4 3 3 1 2 2 4 0 1 2]\n [2 3 2 3 3 3 3 2 3 3 2 3 2 1 3 0 2 4 2 3 1]\n [4 1 6 2 2 2 3 1 3 3 5 2 3 1 2 1 3 2 2 0 2]\n [2 5 0 4 4 1 1 3 1 2 4 3 1 4 3 3 2 0 2 4 1]\n [1 2 2 0 2 4 3 4 3 3 1 1 1 3 3 3 1 4 4 4 1]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}